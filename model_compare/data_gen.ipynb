{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdata_action_train = pd.read_hdf('./data/action_train_with_neg_goodsex.h5', key='df', mode='r')\n",
    "# jdata_action_test = pd.read_hdf('./data/action_test_with_neg_goodsex.h5', key='df', mode='r')\n",
    "jdata_comment = pd.read_csv('./raw/jdata_comment.csv',sep=',')\n",
    "jdata_product = pd.read_csv('./raw/jdata_product.csv',sep=',')\n",
    "jdata_shop = pd.read_csv('./raw/jdata_shop.csv',sep=',')\n",
    "jdata_user = pd.read_csv('./raw/jdata_user.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jdata_action_train = jdata_action_train[:-5000000]\n",
    "jdata_action_train = jdata_action_train.merge(jdata_product[['sku_id','brand','shop_id','cate']], on='sku_id', how='left')\n",
    "jdata_action_train = jdata_action_train.merge(jdata_user[['user_id','age','city']], on='user_id', how='left')\n",
    "jdata_action_train= jdata_action_train.merge(jdata_shop[['shop_id','fans_num','shop_score']], on='shop_id', how='left')\n",
    "# jdata_action_train= jdata_action_train.merge(jdata_comment[['sku_id','comments']], on='sku_id', how='left')\n",
    "jdata_action_train =jdata_action_train.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jdata_action_test = jdata_action_test[:-1000000]\n",
    "jdata_action_test = jdata_action_test.merge(jdata_product[['sku_id','brand','shop_id','cate']], on='sku_id', how='left')\n",
    "jdata_action_test = jdata_action_test.merge(jdata_user[['user_id','age','city']], on='user_id', how='left')\n",
    "jdata_action_test= jdata_action_test.merge(jdata_shop[['shop_id','fans_num','shop_score']], on='shop_id', how='left')\n",
    "# jdata_action_train= jdata_action_train.merge(jdata_comment[['sku_id','comments','good_comments','bad_comments']], on='sku_id', how='left')\n",
    "jdata_action_test = jdata_action_test.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "jdata_action_train = jdata_action_train.sample(frac=1).reset_index(drop=True)\n",
    "label = jdata_action_train['label']\n",
    "jdata_action_train = jdata_action_train[['label','age','city','brand','shop_id','cate','fans_num','shop_score','user_id','sku_id']]\n",
    "param = {'num_leaves': 100, \n",
    "         'objective': 'binary',\n",
    "         'metric': ['auc', 'binary_logloss']\n",
    "        }\n",
    "train_data = lgb.Dataset(jdata_action_train, label=label, feature_name=['label','age','city','brand','shop_id','cate','fans_num','shop_score','user_id','sku_id'], categorical_feature=['age','city','brand','shop_id','cate','user_id','sku_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python3/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'binary_logloss-mean': [0.5785541791023128],\n",
       " 'binary_logloss-stdv': [2.3061790360440876e-08],\n",
       " 'auc-mean': [1.0],\n",
       " 'auc-stdv': [0.0]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_round = 1\n",
    "lgb.cv(param, train_data, num_round, nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized memory....\n"
     ]
    }
   ],
   "source": [
    "print('Optimized memory....')\n",
    "cols_int8 = ['label','age']\n",
    "cols_int16 = ['city','cate']\n",
    "cols_int32 = ['shop_id','brand','user_id','sku_id','fans_num']\n",
    "cols_int64 = []\n",
    "for col in cols_int8:\n",
    "    jdata_action_train[[col]] = jdata_action_train[[col]].astype('int8', errors='ignore')\n",
    "for col in cols_int16:\n",
    "    jdata_action_train[[col]] = jdata_action_train[[col]].astype('int16', errors='ignore')\n",
    "for col in cols_int32:\n",
    "    jdata_action_train[[col]] = jdata_action_train[[col]].astype('int32', errors='ignore')\n",
    "for col in cols_int64:\n",
    "    jdata_action_train[[col]] = jdata_action_train[[col]].astype('int64', errors='ignore')\n",
    "\n",
    "### 转换格式，拿到cate_memo\n",
    "valid_cols = ['label','age','city','brand','shop_id','cate','fans_num','shop_score','user_id','sku_id']\n",
    "jdata_action_train = jdata_action_train[valid_cols]\n",
    "\n",
    "# df2libffm(jdata_action_train, y='label', save_file='./data/train_ffm_model.txt', non_categorical_cols = ['fans_num','shop_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimized memory....')\n",
    "cols_int8 = ['label','age']\n",
    "cols_int16 = ['city','cate']\n",
    "cols_int32 = ['shop_id','brand','user_id','sku_id']\n",
    "cols_int64 = []\n",
    "for col in cols_int8:\n",
    "    jdata_action_test[[col]] = jdata_action_test[[col]].astype('int8', errors='ignore')\n",
    "for col in cols_int16:\n",
    "    jdata_action_test[[col]] = jdata_action_test[[col]].astype('int16', errors='ignore')\n",
    "for col in cols_int32:\n",
    "    jdata_action_test[[col]] = jdata_action_test[[col]].astype('int32', errors='ignore')\n",
    "for col in cols_int64:\n",
    "    jdata_action_test[[col]] = jdata_action_test[[col]].astype('int64', errors='ignore')\n",
    "\n",
    "### 转换格式，拿到cate_memo\n",
    "valid_cols = ['label','age','city','brand','shop_id','cate','fans_num','shop_score','user_id','sku_id']\n",
    "jdata_action_test = jdata_action_test[valid_cols]\n",
    "\n",
    "df2libffm(jdata_action_test, y='label', save_file='./data/test_ffm_model.txt', non_categorical_cols = ['fans_num','shop_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def df2libffm(df, save_file=None, y=None, non_categorical_cols = []) :\n",
    "    \"\"\"\n",
    "    df: data source, should be pandas dataframe\n",
    "    save_file: save file name, if None, will skip saving action\n",
    "    y: label columns name in the pandas dataframe\n",
    "    non_categorical_cols: columns in this list will not be one hot encoder. \n",
    "       example: \n",
    "           price : 0.99$\n",
    "           click rate: 0.03\n",
    "    \"\"\"\n",
    "    assert y is not None\n",
    "\n",
    "    row_cnt = df.shape[0]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        y: df[y]\n",
    "    })\n",
    "\n",
    "    print(\"out.shape:\", out.shape)\n",
    "    df = df.drop(columns=[y], axis=1)\n",
    "\n",
    "    feature_base = 0\n",
    "    \n",
    "\n",
    "    for idx, col in enumerate(df.columns.tolist()) :\n",
    "        dt = datetime.datetime.now()\n",
    "        print( str(dt), idx, col)\n",
    "\n",
    "        cur_field_id = idx\n",
    "        field_series = pd.Series([cur_field_id] * row_cnt).astype(str)\n",
    "\n",
    "        if col in non_categorical_cols :\n",
    "            # if not categorical feature, do not consider how many different values\n",
    "            feature_series = pd.Series([feature_base] * row_cnt).astype(str)\n",
    "            feature_base += 1\n",
    "            value_series = df[col].astype(str)\n",
    "\n",
    "            new_col = field_series + \":\" + feature_series + \":\" + value_series\n",
    "            out[str(cur_field_id)] = new_col.values\n",
    "        else :\n",
    "            # if is categorical feature\n",
    "            ### 使用s.astype(cate_type)进行转换\n",
    "            \n",
    "            ## 为每一个category特征编号\n",
    "            feature_series = df[col].astype('category').values.codes  \n",
    "            ## 编号加上base（前一列的最大编号）\n",
    "            feature_series = feature_series + feature_base\n",
    "            feature_series = pd.Series(feature_series).astype(str)\n",
    "            ## 更新base\n",
    "            feature_base += feature_series.unique().shape[0]\n",
    "            print(\"next feature base:\", feature_base)\n",
    "            \n",
    "            new_col = field_series + \":\" + feature_series + \":1\" \n",
    "            out[str(cur_field_id)] = new_col.values\n",
    "            \n",
    "\n",
    "    if save_file:\n",
    "        file_name = save_file\n",
    "        if not file_name.endswith(\".txt\"):\n",
    "            file_name += \".txt\"\n",
    "        print(\"save file name:\", file_name)\n",
    "        out.to_csv(file_name, sep=\" \", header=False, index=False)\n",
    "    else:\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
